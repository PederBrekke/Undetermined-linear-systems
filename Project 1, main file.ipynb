{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bd146c5",
   "metadata": {},
   "source": [
    "# Candidate number: 10006\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41c44b1",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9a91a6",
   "metadata": {},
   "source": [
    "In this project we will work with solving undertermined linear systems, where our project contains three separate but closely linked tasks. Generally, we will try to solve a constraint optimization problem in finding $x_{min}$, this by using a range of different methods. This will in the end be applied to a more real-life problem, namely single channel source separation for images. In some settings, we will also compare our developed implementations for finding $x_{min}$, to some of NumPy's own functions. Here, we are both interested in accuracy and runtime of our functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13000940",
   "metadata": {},
   "source": [
    "## TASK 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d791536",
   "metadata": {},
   "source": [
    "### 1 a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8980b6b4",
   "metadata": {},
   "source": [
    "We consider a matrix **A** $\\in {\\rm I\\!R}^{m \\times n}$, given $m = 2$ and $n = 3$. Further, our linear system is on the form $Ax = y$, where $x \\in {\\rm I\\!R}^n$ and $y \\in {\\rm I\\!R}^m$. We then look for two examples of A and y such that the linear system <br> **(1)** does not have a solution. <br>\n",
    "**(2)** has infinetly many solutions.\n",
    "<br>\n",
    "<br>\n",
    "**For (1):** <br>\n",
    "If Gauss-elimination on a linear system gives us a row on the form [0,0,...,0|non-zero]; our matrix is inconsistent. This simplest example of this is if we choose our matrix **A** to be the null matrix, while choosing any non-zero vector **y**. Using that $m = 2$ and $n = 3$, one example could look like this:\n",
    "\n",
    "$A = \n",
    "\\left(\\begin{array}{cc} \n",
    "0 & 0 & 0\\\\\n",
    "0 & 0 & 0\n",
    "\\end{array}\\right)\n",
    "$ ,\n",
    "$\n",
    " y =\n",
    "\\left(\\begin{array}{cc} \n",
    "1\\\\\n",
    "2\n",
    "\\end{array}\\right)\n",
    "$ ,with the matrix for the system of linear equations would look like this $\n",
    "\\left[\n",
    "\\begin{array}{ccc|c}\n",
    "0 & 0 & 0 & 1 \\\\\n",
    "0 & 0 & 0 & 2 \\\\\n",
    "\\end{array}\n",
    "\\right]\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d72ea7c",
   "metadata": {},
   "source": [
    "Another example would be if first have to Gauss-eliminate to get a zero-row. For this to happen, we must have that two or more rows in A are scalar by some factor _a_ of eachother, while their corresponding values in **y** are not scalar by the same factor _a_. For example, **A** and **y** could be given as such:\n",
    "\n",
    "$A = \n",
    "\\left(\\begin{array}{cc} \n",
    "1 & 2 & 4\\\\\n",
    "2 & 4 & 8\n",
    "\\end{array}\\right)\n",
    "$ ,\n",
    "$\n",
    " y =\n",
    "\\left(\\begin{array}{cc} \n",
    "12\\\\\n",
    "3\n",
    "\\end{array}\\right)\n",
    "$   ,with the matrix for the system of linear equations would be $\n",
    "\\left[\n",
    "\\begin{array}{ccc|c}\n",
    "1 & 2 & 4 & 12 \\\\\n",
    "2 & 4 & 8 & 3 \\\\\n",
    "\\end{array}\n",
    "\\right]\n",
    "$ $\\sim$ $\n",
    "\\left[\n",
    "\\begin{array}{ccc|c}\n",
    "1 & 2 & 4 & 12 \\\\\n",
    "0 & 0 & 0 & -21 \\\\\n",
    "\\end{array}\n",
    "\\right]\n",
    "$\n",
    "\n",
    "Both of the examples of **A** and **y** above gives a linear system of equations without a solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861dd3b9",
   "metadata": {},
   "source": [
    "**For (2):** <br>\n",
    "For a system of linear equations to have infinetly many solutions, we must at least one free variable in our gauss-elimination of our matrix [**A**,**y**]. That means that some of our columns in **A** must be linearly dependent. Two examples for **A** and **y** of this could be as such:\n",
    "\n",
    "$$A = \n",
    "\\left(\\begin{array}{cc} \n",
    "1 & 2 & 3\\\\\n",
    "2 & 4 & 5\n",
    "\\end{array}\\right)\n",
    ",\n",
    " y =\n",
    "\\left(\\begin{array}{cc} \n",
    "9\\\\\n",
    "17\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "or\n",
    "\n",
    "$$A = \n",
    "\\left(\\begin{array}{cc} \n",
    "1 & 4 & -2\\\\\n",
    "3 & 8 & -4\n",
    "\\end{array}\\right)\n",
    ",\n",
    " y =\n",
    "\\left(\\begin{array}{cc} \n",
    "3\\\\\n",
    "9\n",
    "\\end{array}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eb4379",
   "metadata": {},
   "source": [
    "### 1 b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf5f849",
   "metadata": {},
   "source": [
    "Given a matrix **A** $\\in {\\rm I\\!R}^{m \\times n}$  , we want to prove that $A^TA$ and $AA^T$ are both symmetric and are positive semi-definite. We start by proving that $A^TA$ and $AA^T$ are both symmetric for any real matrix **A**.\n",
    "\n",
    "$$\n",
    "(A^TA)^T = A^T(A^T)^T = A^TA\n",
    "$$\n",
    "Similarly, \n",
    "$$\n",
    "(AA^T)^T = (A^T)^TA^T = AA^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39846abd",
   "metadata": {},
   "source": [
    "In the first equality, we used the general rule that for any matrices **B** , **C**, it can be shown that $(BC)^T = C^TB^T$. In the second equality, we use that for any matrix **B**, we have that $(B^T)^T = B$. Thus, for any given matrix **A** $\\in {\\rm I\\!R}^{m \\times n}$, we have that $(A^TA)^T = A^TA$, and $(AA^T)^T = AA^T$. Since we have shown that $A^TA$ and $AA^T$ are both equal to their transposed, we conclude that they must be symmetric. <br> <br>\n",
    "Now we will prove that $A^TA$ and $AA^T$ are both positive semi-definite. We know that a matrix B is positive semi-definite if $x^TBx \\geq 0$ for all $ x \\in {\\rm I\\!R}^{n}$ , $x \\neq 0$. If this is a strict inequality, we call **B** positive definite. Inserting $A^TA$ for **B** in our equation gives us the following:\n",
    "\n",
    "$$\n",
    "x^T(A^TA)x = x^TA^TAx = (Ax)^TAx = \\lVert Ax \\rVert^2 \\geq 0\n",
    "$$\n",
    "Similarly,\n",
    "$$\n",
    "x^T(AA^T)x = x^TAA^Tx = (A^Tx)^TA^Tx = \\lVert A^Tx \\rVert^2 \\geq 0 \n",
    "$$\n",
    "\n",
    "Thus $A^TA$ and $AA^T$ are both symmetric and positive semi-definite. $ \\square $\n",
    "\n",
    "If we further assume that our matrix **A** has full rank, i.e. rank(A) = m,  we now choose to look at the invertibility of $AA^T$ and $A^TA$. Do to this, we look at a vector $ x \\in Null(A)$, such that $Ax = 0$. \n",
    "$$\n",
    "A^TAx = 0 \\Rightarrow x \\in Null(A^TA)\n",
    "$$\n",
    "The nullspace of **A** must necessarily be greater than or equal to the nullspace of $A^TA$; $Null(A^TA) \\subseteq Null(A)$. Similarly, looking at a vector $ y \\in Null(A^TA)$, such that $A^TAy = 0$. Then,\n",
    "\n",
    "$$\n",
    "y^TA^TAy =  (Ay)^TAy = 0  \\Rightarrow y \\Rightarrow Ay = 0 \\Rightarrow  y \\in Null(A)\n",
    "$$\n",
    "\n",
    "Here we get that the nullspace of $A^TA$ must be greater than or equal to the nullspace of **A**; $Null(A) \\subseteq Null(A^TA)$. Combining these two results, we get that \n",
    "$$\n",
    "Null(A) = Null(A^TA) \\Rightarrow rank(A) = rank(A^TA)\n",
    "$$\n",
    "\n",
    "Since A was arbitrairly chosen as a matrix with full rank m, our proof is also valid for $A^T$. \n",
    "Note that we assumed **A** $\\in {\\rm I\\!R}^{m \\times n}$, such that rank(**A**) = m in case of a full rank matrix **A** where m < n. Then,\n",
    "$$\n",
    "rank(A) = rank(A^TA) = rank(AA^T) = m\n",
    "$$\n",
    "\n",
    "Since  $A^TA \\in {\\rm I\\!R}^{n \\times n}$ and $AA^T \\in {\\rm I\\!R}^{m \\times m}$, we can now clearly see that $AA^T$ has full rank and is therefore invertible, while $A^TA$ does not have full rank and consequently is not invertible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e9fb6e",
   "metadata": {},
   "source": [
    "### 1 c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc63def",
   "metadata": {},
   "source": [
    "Given the Lagrange function,\n",
    "$$ \n",
    "L(x,\\lambda) = x^Tx + \\lambda^T(Ax - y)\n",
    "$$\n",
    "\n",
    "we now look to find its gradient, both with respect to **x** and to $\\lambda$. We have that   $ \\lambda \\in {C}^{m}$, $ y \\in {\\rm I\\!R}^{m}$. We start by looking at the gradient with respect to **x**:\n",
    "\n",
    "$$\n",
    "\\nabla_x L(x,\\lambda) = \\frac{d}{dx} ( x^Tx) + \\frac{d}{dx} (\\lambda^T (Ax-y))\n",
    "$$\n",
    "\n",
    "Here, we have denote the partial derivate as $\\frac{d}{dx}$, by which we mean $\\frac{d}{dx} = \\left( \\frac{\\partial}{\\partial x_1}, \\frac{\\partial}{\\partial x_2}, \n",
    " \\ldots , \\frac{\\partial}{\\partial x_n}\\right)$, since our **x** is a vector on the form $(x_1, x_2, ... , x_n)^T$. Looking at our first term, $x^Tx$, we can see that this is simply the sum of the squared elements in **x**. <br><br>\n",
    " $$\n",
    " x^Tx = [x_1,x_2, ... , x_n]  \\begin{bmatrix}x_1\\\\x_2\\\\\\vdots\\\\x_n\\end{bmatrix} = x_1^2 + x_2^2 + ... + x_n^2\n",
    "$$\n",
    "\n",
    "Putting this expression in for $x^Tx$, we can calculate the first part of our gradient:\n",
    "\n",
    "$$\n",
    "\\tag{1}\n",
    "\\frac{d}{dx} ( x^Tx) = \\left( \\frac{\\partial}{\\partial x_1}, \\frac{\\partial}{\\partial x_2}, \n",
    " \\ldots , \\frac{\\partial}{\\partial x_n}\\right)  (x_1^2 + x_2^2 + ... + x_n^2) = \\begin{bmatrix}2x_1\\\\2x_2\\\\\\vdots\\\\2x_n\\end{bmatrix} = 2x\n",
    "$$\n",
    "\n",
    "Now we look at our second term of the original equation. We notice that both $\\lambda^T$ and **y** are independent of **x**, which simplifies our equation.\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{d}{dx} (\\lambda^T (Ax-y)) =  \\frac{d}{dx}(\\lambda^TAx)\n",
    "$$\n",
    "\n",
    "We now write out $\\lambda^TAx$:\n",
    "\n",
    "$$\n",
    "\\lambda^TA\\boldsymbol{x} = [\\lambda_1,\\lambda_2, ..., \\lambda_m]\\begin{bmatrix}a_{11}&a_{12}&\\cdots&a_{1n}\\\\a_{21}&\\ddots&&\\vdots\\\\\\vdots&&&\\\\a_{m1}&\\cdots&&a_{mn}\\end{bmatrix}\n",
    "\\begin{bmatrix}x_1\\\\x_2\\\\\\vdots\\\\x_n\\end{bmatrix}\n",
    "= [\\lambda_1,\\lambda_2, ..., \\lambda_m] \\begin{bmatrix}a_{11}x_1+a_{12}x_2+\\ldots+a_{1n}x_n\\\\\n",
    "a_{21}x_1+a_{22}x_2+\\ldots+a_{2n}x_n\\\\\\vdots\\\\\n",
    "a_{m1}x_1+a_{m2}x_2+\\ldots+a_{mn}x_n\\end{bmatrix} \n",
    "$$\n",
    "<br><br>\n",
    "$$ \n",
    "\\tag{2}\n",
    "\\Rightarrow \\lambda^TA\\boldsymbol{x}= \\lambda_1(a_{11}x_1+a_{12}x_2+\\ldots+a_{1n}x_n) + \\lambda_2(a_{21}x_1+a_{22}x_2+\\ldots+a_{2n}x_n) + ... + \\lambda_m(a_{m1}x_1+a_{m2}x_2+\\ldots+a_{mn}x_n)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Rightarrow \\frac{d}{dx}(\\lambda^TAx) = \\left( \\frac{\\partial}{\\partial x_1}, \\frac{\\partial}{\\partial x_2}, \n",
    " \\ldots , \\frac{\\partial}{\\partial x_n}\\right) (\\lambda^TAx) = \\begin{bmatrix}\\lambda_1a_{11}+\\lambda_2a_{21}+\\ldots+\\lambda_ma_{m1}\\\\\n",
    "\\lambda_1a_{12}+\\lambda_2a_{22}+\\ldots+\\lambda_ma_{m2}\\\\\\vdots\\\\\n",
    "\\lambda_1a_{1n}+\\lambda_2a_{2n}+\\ldots+\\lambda_ma_{mn}\\end{bmatrix} = A^T\\lambda\n",
    "$$\n",
    "\n",
    "Now we can write out $ \\nabla_x L(x,\\lambda) = 0$ as such:\n",
    "\n",
    "$$\n",
    "\\tag{3}\n",
    "\\nabla_x L(x,\\lambda) = 2x + A^T \\lambda = 0 \\Rightarrow  x_{min} = - \\frac{A^T \\lambda}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58002b1d",
   "metadata": {},
   "source": [
    "Now we do the same for $ \\nabla_\\lambda L(x,\\lambda)$:\n",
    "$$\n",
    "\\nabla_\\lambda L(x,\\lambda) = \\frac{d}{d\\lambda} (x^Tx +\\lambda^T (Ax-y)) =  \\frac{d}{d\\lambda}(\\lambda^TAx) + \\frac{d}{d\\lambda}(-\\lambda^Ty) \n",
    "$$\n",
    "\n",
    "Similarly, we have defined the partial derivate $\\frac{d}{d\\lambda}$, by which we mean $\\frac{d}{d\\lambda} = \\left( \\frac{\\partial}{\\partial \\lambda_1}, \\frac{\\partial}{\\partial \\lambda_2}, \n",
    " \\ldots , \\frac{\\partial}{\\partial \\lambda_n}\\right)$. For the first term, we use equation (2) from above. <br><br>\n",
    "$$\n",
    "\\frac{d}{d\\lambda}(\\lambda^TAx) = \\frac{d}{d\\lambda} (\\lambda_1(a_{11}x_1+a_{12}x_2+\\ldots+a_{1n}x_n) + \\lambda_2(a_{21}x_1+a_{22}x_2+\\ldots+a_{2n}x_n) + ... + \\lambda_n(a_{n1}x_1+a_{n2}x_2+\\ldots+a_{nn}x_n))\n",
    "$$\n",
    "$$\n",
    " = \\begin{bmatrix}a_{11}x_1+a_{12}x_2+\\ldots+a_{1n}x_n\\\\\n",
    "a_{21}x_1+a_{22}x_2+\\ldots+a_{2n}x_n\\\\\\vdots\\\\\n",
    "a_{n1}x_1+a_{n2}x_2+\\ldots+a_{nn}x_n\\end{bmatrix} = Ax\n",
    "$$\n",
    "\n",
    "Now we find the derivative for the second term.\n",
    "$$\n",
    "\\frac{d}{d\\lambda}(-\\lambda^Ty) = \\frac{d}{d\\lambda} (-y_1\\lambda_1 - y_2\\lambda_2 - ... - y_n\\lambda_n)\n",
    "$$\n",
    "$$\n",
    "\\left( \\frac{\\partial}{\\partial \\lambda_1}, \\frac{\\partial}{\\partial \\lambda_2}, \n",
    " \\ldots , \\frac{\\partial}{\\partial \\lambda_n}\\right)(-y_1\\lambda_1 - y_2\\lambda_2 - ... - y_n\\lambda_n) = \\begin{bmatrix}-y_1\\\\\n",
    "-y_2\\\\\\vdots\\\\\n",
    "-y_n\\end{bmatrix} = -y\n",
    "$$\n",
    "\n",
    "Combining these two results, and setting$\\nabla_\\lambda L(x,\\lambda) = 0$, we get the following:\n",
    "\n",
    "$$\n",
    "\\tag{4}\n",
    "\\nabla_\\lambda L(x,\\lambda) = Ax - y = 0\n",
    "\\Rightarrow Ax = y \n",
    "$$\n",
    "\n",
    "Putting (3) into (4), we get the following:\n",
    "\n",
    "$$\n",
    "Ax - y= A(- \\frac{A^T \\lambda}{2})- y = 0 \\Rightarrow \\lambda=-2(AA^T)^{-1} y \n",
    "$$\n",
    "\n",
    "We then put this new expression for $\\lambda$ into (3), and arrive at our desired result.\n",
    "\n",
    "$$\n",
    "\\tag{5}\n",
    "x_{min} = - \\frac{A^T \\lambda}{2} = - \\frac{A^T( -2(AA^T)^{-1} y) }{2} = A^T(AA^T)^{-1}y\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead9b945",
   "metadata": {},
   "source": [
    "### 1 d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24885f33",
   "metadata": {},
   "source": [
    "Given $A^T = QR$, where $Q \\in {\\rm I\\!R}^{n \\times m}$ is orthogonal and $R \\in {\\rm I\\!R}^{m \\times m}$ is upper triangular, we can further rewrite (5). We also aknowledge that $(R^{-T}) = (R^T)^{-1} = (R^T)^{-1}$ in our usage of a QR decomposition. Furthermore, we note that the orthogonality of Q implies that $Q^TQ = QQ^T = I$, where I is the identity matrix. We can then rewrite (5) as such: <br><br>\n",
    "$$\n",
    "x_{min} = A^T(AA^T)^{-1}y = (QR)((QR)^TQR)^{-1}y = QR(R^TR)^{-1}y\n",
    "$$\n",
    "$$\n",
    "\\tag{6}\n",
    "x_{min} = QRR^{-1}R^{-T}y = QR^{-T} y\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74fd4a5",
   "metadata": {},
   "source": [
    "To solve the equation above, we introduce some code which performs Gram-Schmidt orthonornalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bbec631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries for the entire project\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.linalg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1932386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_schmidt(A):\n",
    "    \n",
    "    # Define n and m\n",
    "    n,m = A.shape\n",
    "    \n",
    "    # Initialize empty Q and R \n",
    "    Q = np.zeros((m,n))\n",
    "    R = np.zeros((m,m))\n",
    "    \n",
    "    # Initialize first columns in Q and R\n",
    "    u0 = A[:,0]\n",
    "    q0 = u0/sp.linalg.norm(u0, 2)\n",
    "    Q[0] = q0\n",
    "    R[0,0] = np.inner(A[:,0],q0)\n",
    "    \n",
    "    # Calculate Q and R\n",
    "    for k in range(1, m):\n",
    "        u_k = A[:,k].astype(np.float64)\n",
    "        for j in range(0, k):\n",
    "            r = np.inner(A[:,k],Q[j])\n",
    "            R[j,k] = r\n",
    "            u_k -= r*Q[j].astype(np.float64)\n",
    "            \n",
    "        q_k = u_k / sp.linalg.norm(u_k,2)\n",
    "        Q[k] = q_k\n",
    "        R[k,k] = np.inner(A[:,k],Q[k])\n",
    "    \n",
    "    return Q.T, R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c30d1d",
   "metadata": {},
   "source": [
    "### 1 e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4141b30f",
   "metadata": {},
   "source": [
    "Now that we have a way of finding the QR decompostion of a given matrix **A**, we now want to solve equation (6) for $x_{min}$. This would seemingly imply that we have to find both Q and R, and then find the inverse-transpose of R. Since we know that finding the inverse of matrices can be both computationally demanding and possibly prone to computer float errors, we want to find a way to avoid calculating the inverse of any matrix. We therefore rewrite equation (6) in the following way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dec43f2",
   "metadata": {},
   "source": [
    "$$\n",
    "x_{min} = QR^{-T} y \\Rightarrow R^TQ^Tx_{min} = R^TQ^TQR^{-T}y = y \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6e0704",
   "metadata": {},
   "source": [
    "We now set $Q^Tx_{min} = z$, which gives us these two equations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4fcb7e",
   "metadata": {},
   "source": [
    "$$\n",
    "Q^Tx_{min} = z\n",
    "$$\n",
    "$$\n",
    "R^Tz = y\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47aed28",
   "metadata": {},
   "source": [
    "Since $R$ is upper-triangular, we know that $R^T$ is lower-triangular. Therefore we can use backwards substitution to solve for z, and then using our calculated z to solve for $x_{min}$ in our first equation. This is implemented in the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b590894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QR_solver(Q, R, y):\n",
    "    \n",
    "    #calculates our z using backwards substitution\n",
    "    z = sp.linalg.solve_triangular(R.T, y, lower=True)\n",
    "    x_min = Q @ z\n",
    "    return x_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25283828",
   "metadata": {},
   "source": [
    "### 1 f) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fd2870",
   "metadata": {},
   "source": [
    "Now that we have implemented a way of solving our system of equations, we wish to compare our method of QR decompositioning to the far more complex and \"fine-tuned\" SciPy implementation; scipy.linalg.solve. Here, we are both interested in the run time of each method for a given set of systems, as well as how accurate solutions they each give. To measure the run time **%%timeit** will be used, and for accuracy we will measure $\\|x_{true} - x_{approx}\\|$  for a given solution **y**.  <br> \n",
    "To generate a random matrix **A**, we will use some of the handed out code, shown below. The function `generate_A()` takes in the dimensions n and m of **A**, and returns a full rank matrix **A** such that $A \\in {\\rm I\\!R}^{m \\times n}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b196dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HANDED OUT CODE\n",
    "\n",
    "# Generate matrix A \\in \\mathbb{R}^{m \\times n}\n",
    "\n",
    "def generate_A(m,n):\n",
    "    \"\"\"\n",
    "    Generates m times n with correlated columns.\n",
    "    Input:\n",
    "        m: int, first dimension of A\n",
    "        n: int, second dimension of A\n",
    "    output:\n",
    "        A: (m,n) array\n",
    "    \"\"\"\n",
    "\n",
    "    cov_eigvecs = np.random.uniform(-1.0,1.0,(n,n))\n",
    "    cov = cov_eigvecs.T @ cov_eigvecs\n",
    "    v = np.sqrt(np.diag(cov))\n",
    "    outer_v = np.outer(v, v)\n",
    "    corr = cov / outer_v\n",
    "    corr[cov == 0] = 0\n",
    "    chol = sp.linalg.cholesky(corr, lower=True) \n",
    "    A = np.random.normal(0, 1.0,(m,n))\n",
    "    A = np.dot(A,chol.T)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2a19452",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2048\n",
    "n = 8096\n",
    "A = generate_A(m,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04b5796",
   "metadata": {},
   "source": [
    "Next, we introduce even more handed out code. The code block below generates **N** sets of **x** and **y** vectors, such that $Ax =y$ for any given pair. These **x**- and **y**-vectors are stored in **X** and **Y**, respectively. As requested, we set $ N = 100$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a915582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8096, 100)\n",
      "(2048, 100)\n"
     ]
    }
   ],
   "source": [
    "N = 100 # Number of test data we want to generate\n",
    "\n",
    "# Generate solutions X columnwise, X[:,i] to access i-th vector\n",
    "X = np.random.normal(0.0,1.0,(A.shape[1],N))\n",
    "\n",
    "# Generate left hand sides Y columnwise Y[:,i] to access lhs\n",
    "Y = np.dot(A,X)\n",
    "\n",
    "# Doublecheck shapes\n",
    "print(X.shape) # Expect (n,N)\n",
    "print(Y.shape) # Expect (m,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc68c970",
   "metadata": {},
   "source": [
    "Now we have implemented the necessary code, we can start comparing our two equation solvers. To use `scipy.linalg.solve()`, we must precalculate the matrix $AA^T$, while for`QR_solver()` it is necessary to precalculate our QR-decomposition of **A**. We start by looking at the runtime of constructing $AA^T$ in the first block, and then look at the runtime for our QR-decomposition in the second block. Here we will re-run both code blocks 6 times to get a good standard deviation of our runtime.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78cd6478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291 ms ± 6.7 ms per loop (mean ± std. dev. of 6 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 6\n",
    "AAT = A@A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7451c2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.1 s ± 1.46 s per loop (mean ± std. dev. of 6 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 6\n",
    "Q,R = gram_schmidt(A.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4b820b",
   "metadata": {},
   "source": [
    "From the two code-blocks above, we can clearly infer that QR-decomposition the way we have implemented it, is far more time-consuming than calculating $AA^T$. While calculating $AA^T$ takes us less than half a second, the average runtime for our QR-decomposition takes over 30 seconds; over 50 times as long.\n",
    "\n",
    "We now wish to use these compositions to solve the test data that we generated in a few code-blocks earlier. Here we use our already found QR-decomposition in `QR_solver()`, and compare its runtime to NumPy's `numpy.linalg.solve()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eac600e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find QR decomposition\n",
    "Q,R = gram_schmidt(A.T)\n",
    "\n",
    "#Calculate matrix AA^T\n",
    "AAT = A @ A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c84c3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.1 s ± 39.8 ms per loop (mean ± std. dev. of 6 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 6\n",
    "# Solve with np.linalg.solve for every generated y,\n",
    "# and finding the total runtime\n",
    "for y in Y.T:\n",
    "    z = np.linalg.solve(AAT,y)\n",
    "    x_min = A.T @ z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "722bd932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "982 ms ± 3.15 ms per loop (mean ± std. dev. of 6 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 6\n",
    "# Solve with QR-decomposition for every generated y,\n",
    "# and finding the total runtime\n",
    "for y in Y.T:\n",
    "    QR_solver(Q,R,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416b1b2a",
   "metadata": {},
   "source": [
    "As we can see, the QR-decomposition method is significantly faster than `numpy.linalg.solve()`at computing $x_{min}$ when it is being run for large data sets of system of equations. While the NumPy implementation uses closer to 13 seconds for $N = 100$ different y-vectors, our `QR_solver()` uses closer to 1 second; less than a tenth of the runtime. Combining these results with the runtime of the pre-calculations, it seems that QR-decomposition performs best timewise when dealing with a very large data set ( having N being large). For smaller N, our way of computing the QR-decomposition of **A** seems to be too time-costly for it to be a more viable option than simply calculating $AA^T$, and then using  `numpy.linalg.solve()`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55f26dd",
   "metadata": {},
   "source": [
    "One can also ask if these implementations differ in accuracy, or differently phrased; what is the difference in magnitude of $\\|x_{true} - x_{approx}\\|$ for our two implementations? We implement some code below to check whether $\\|x_{true} - x_{approx}\\|$ differs for  `numpy.linalg.solve()` and `QR_solver()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b56e21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate x_min with QR_solver() for each y and store in list\n",
    "x_min_QR = [QR_solver(Q,R,y) for y in Y.T]\n",
    "# Create list of norms of difference between x_true and x_min found\n",
    "QR_norms = [np.linalg.norm(x_min_QR[i] - X.T[i]) for i in range(len(X.T))]\n",
    "\n",
    "# Calculate x_min with np.linalg.solve() for each y and store in list\n",
    "x_min_numpy = [A.T @ np.linalg.solve(AAT,y) for y in Y.T]\n",
    "# Create list of norms of difference between x_true and x_min found\n",
    "numpy_norms = [np.linalg.norm(x_min_numpy[i] - X.T[i]) for i in range(len(X.T))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "065af092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between norms of QR and np.linalg.solve():  8.038873388460929e-14\n"
     ]
    }
   ],
   "source": [
    "norm_diff = np.array(QR_norms) - np.array(numpy_norms)\n",
    "print(\"Difference between norms of QR and np.linalg.solve(): \", np.linalg.norm(norm_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46e85db",
   "metadata": {},
   "source": [
    "As we can see, the accuracy of `numpy.linalg.solve()` and `QR_solver()` do not differ in norm from eachother from $x_{true}$ other than what can be expected from the possible floating errors made by the computer. The two implementations seem to be equally accurate in finding $x_{min}$, and are therefore highly useful in returning a solution. Since we know that there is a unique solution $x_{min}$, it is reasonable to say that both our methods converge towards said solution. We should also note that all though both $x_{true}$ and $x_{min}$ are solutions to our system, the norm of $x_{min}$ is significantly lower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb205dd3",
   "metadata": {},
   "source": [
    "## TASK 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d625f4",
   "metadata": {},
   "source": [
    "### 2 a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318333e7",
   "metadata": {},
   "source": [
    "We now switch our focus to Tikhonov regularisation, which tries to solve $Ax = y$ for **x** by using a combination of a least-squares solution and a weighted constraint solution. Our solution then fufills the following equation:\n",
    "$$\n",
    "x_r = \\underset{x\\in\\mathbb{R}^n}{\\text{arg min}}\\hspace{0.3cm} \\|Ax-y\\|^2+\\mu\\|x\\|^2.\n",
    "$$\n",
    "<br>\n",
    "Here, $\\mu$  is our weight, where $\\mu > 0$. To ease notation, we introduce the a function $T(x) = \\|Ax-y\\|^2+\\mu\\|x\\|^2$, such that  <br>  \n",
    "$$\n",
    "\\tag{7} \n",
    "x_r = \\underset{x\\in\\mathbb{R}^n}{\\text{arg min}}\\hspace{0.3cm} T(x).\n",
    "$$\n",
    "<br> \n",
    "\n",
    "Given that a solution of (7) satisfies $\\nabla_xT(x)=0$, we can derive a expression which contains our solution $x_r$. <br><br>\n",
    "$$\n",
    " \\nabla_xT(x) = \\nabla_x(\\|A\\boldsymbol{x}-\\boldsymbol{y}\\|^2+\\mu\\|\\boldsymbol{x}\\|^2)\n",
    "$$\n",
    "\n",
    "Here we can use the results that we found in **TASK 1, 1 c)**, namely that  $\\nabla_z z^Tz = \\nabla_z \\|z\\|^2 = 2z$ and that $\\nabla_x Ax = A^T$. Using this we can already see the derivative of our second term.\n",
    "$$\n",
    "\\nabla_x \\mu\\|x\\|^2 = 2\\mu \\boldsymbol{x} \n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Looking at our first term, we need to apply the chain rule as well as our results from **TASK 1, 1 c)**. <br><br>\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\nabla_x(\\|A\\boldsymbol{x}-\\boldsymbol{y}\\|^2 &= \\frac{\\partial U}{\\partial x} \\cdot \\frac{\\partial }{\\partial U}\\|U\\|^2 , U = A\\boldsymbol{x}-\\boldsymbol{y} \\\\\n",
    " &=  A^T \\cdot(2 \\cdot(A\\boldsymbol{x}-\\boldsymbol{y})) = 2A^TA\\boldsymbol{x}-2A^T\\boldsymbol{y}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "We now combine these two terms to find the final expression for $\\nabla_x T(x)$, as well that we set this gradient equal to zero to find our $x_r$.\n",
    "\n",
    "$$\n",
    " \\nabla_xT(x) = \\nabla_x(\\|A\\boldsymbol{x}-\\boldsymbol{y}\\|^2+\\mu\\|\\boldsymbol{x}\\|^2) = 2A^TA\\boldsymbol{x_r}-2A^T\\boldsymbol{y} + 2\\mu\\boldsymbol{x_r} = 0\n",
    "$$\n",
    "$$\n",
    "\\tag{8}\n",
    "\\Rightarrow   (A^TA+\\mu I)\\boldsymbol{x_r}=A^T\\boldsymbol{y}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb292be",
   "metadata": {},
   "source": [
    "We now want to show that $A^TA + \\mu I$ is symmetric positive definite, SPD. We start by showing that it is symmetric. Our first realization is that $\\mu I$ is SPD for all $\\mu > 0$, as the identity matrix is a diagonal matrix such that $I^T = I$. Furthermore, we have already proven in **TASK 1, 1 b)** that $A^TA$ is symmetric positive semi-definite, which implies that $A^TA + \\mu I$ also must be symmetric; the sum of a symmetric matrix with a diagonal matrix is necessarily symmetric.\n",
    "We now have only have to prove that $A^TA + \\mu I$ is positive definite. We know that a matrix B is positive definite if $x^TBx > 0$ for all $ x \\in {\\rm I\\!R}^{n}$ , $x \\neq 0$ <br> <br>\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x^T(A^TA + \\mu I)x &= x^TA^TAx + x^T\\mu Ix \\\\&=(A^Tx)^Tx + \\mu(Ix)^T(Ix) \\\\\n",
    "&= \\|A^Tx\\|^2 + \\mu\\|Ix\\|^2 \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "As we already have showed in **TASK 1, 1 b)** $\\|A^Tx\\|^2 \\geq 0$ and $\\|Ix\\|^2 \\geq 0$. But, since $ \\mu > 0$, then we have that $\\|A^Tx\\|^2 + \\mu\\|Ix\\|^2 > 0$. Thus, we have proven that $A^TA + \\mu I$ is SPD. This is also sufficient to say that $A^TA + \\mu I$ is invertible. $\\square$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1bf879",
   "metadata": {},
   "source": [
    "### 2 b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6768616c",
   "metadata": {},
   "source": [
    "We now want to use a singular value decompostion, SVD, of our given matrix **A**. This means re-writing our matrix as \n",
    "$$\n",
    "A = U \\Sigma V^T\n",
    "$$\n",
    "Here, $U$ and $V$ are real unitary matrices, while $\\Sigma$ is a diagonal matrix with a given number of singular values along its diagonal. We now put this new expression of our matrix $A$ into (8), using that $B^TB = BB^T = I$ for any real unitary matrix $B$. <br> <br>\n",
    "$$\n",
    "\\begin{aligned}\n",
    "((U \\Sigma V^T)^T(U \\Sigma V^T)+\\mu I)\\boldsymbol{x_r}&=(U \\Sigma V^T)^T\\boldsymbol{y} \\\\\n",
    "(V \\Sigma^T U^TU \\Sigma V^T + \\mu VIV^T)\\boldsymbol{x_r} &= V \\Sigma^T U^T\\boldsymbol{y} \\\\\n",
    "V(\\Sigma^T\\Sigma + \\mu I)V^T\\boldsymbol{x_r} &= V \\Sigma^T U^T\\boldsymbol{y} \\\\\n",
    "(\\Sigma^T\\Sigma + \\mu I)V^T\\boldsymbol{x_r} &= \\Sigma^T U^T\\boldsymbol{y}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "From our result in **TASK 2, 2 a)**, we can use that $\\Sigma^T\\Sigma + \\mu I$  is SPD and thus invertible. This gives us the following expression for $x_r$. <br><br>\n",
    "$$\n",
    "\\boldsymbol{x_r} = V(\\Sigma^T\\Sigma + \\mu I)^{-1}\\Sigma^T U^T\\boldsymbol{y}\n",
    "$$\n",
    "\n",
    "By definition, $\\Sigma$ and $\\Sigma^T$ are diagonal matrices, which means that $\\Sigma\\Sigma^T$, and more importantly $\\Sigma^T\\Sigma + \\mu I$, are diagonal matrices. This further implies that $D = (\\Sigma^T\\Sigma + \\mu I)^{-1}\\Sigma^T$ is a diagonal matrix. Substituting this into our previous expression, we get our wanted result:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{x_r} = VDU^T\\boldsymbol{y}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf61e2",
   "metadata": {},
   "source": [
    "### 2 c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f11f15d",
   "metadata": {},
   "source": [
    "We now create a function `Tikonov_solveSVD()`, which will take in matrices $U$ and $V^T$, an array $S$ containing the singular values of $A$, as well as our weight $\\mu$ and a vector $y$. We then use these inputs to find our $x_r$. \n",
    "\n",
    "Since $\\Sigma\\Sigma^T$ contains the square of the singular values $\\sigma_i$ (followed by zeros filling the remaining entries) along its diagonal, $\\Sigma^T\\Sigma + \\mu I$ has diagonal entries of $\\sigma^2_{i} + \\mu$. Since taking the inverse of a diagonal matrix is equivalent to taking the inverse of every diagonal entry, we get that $(\\Sigma^T\\Sigma + \\mu I)^{-1}$ simply has $\\frac{1}{\\sigma^2_{i} + \\mu}$ as its diagonal entries. Finally this means that $D$ as we defined it in **TASK 2, 2 b)**, has the entries $\\frac{\\sigma_i}{\\sigma^2_{i} + \\mu}$ on its diagonal. Note that our singular values $\\sigma_i$ are sorted in descending order along the diagonal of $\\Sigma$.\n",
    "We now implement the function `Tikonov_solveSVD()` which calculates our $x_r$ using what we just discussed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2975be75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the imput S here is a vector\n",
    "# containing our singular values, not a matrix \n",
    "def Tikonov_solveSVD(U,S,vt,mu,y):\n",
    "\n",
    "    # find dimension of D\n",
    "    n = np.size(vt[0])\n",
    "    m = np.size(U[0])\n",
    "    \n",
    "    # calculate non-zero diagonal entries of D\n",
    "    # here \"diag_entries\" are the non-zero diagonal entries,\n",
    "    # while diag is the completed diagonal\n",
    "    diag = [S[i]/(S[i]**2 + mu) for i in range(len(S))]\n",
    "    \n",
    "    # create diagonal matrix D, and fill in entries along its diagonal\n",
    "    D = np.zeros((n,m))\n",
    "    np.fill_diagonal(D,diag)\n",
    "    \n",
    "\n",
    " \n",
    "    #returns x_r\n",
    "    return vt.T @ D @ U.T @ y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f95c3db",
   "metadata": {},
   "source": [
    "### 2 d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead2ec26",
   "metadata": {},
   "source": [
    "We now want to calculate our $x_r$ using our newly implemented function. To do this, we once again use the previously used `generate_A()` to create our matrix **A**, and then use `numpy.linalg.svd()` to find our matrices $U$, $S$ and $V^T$. Having done that, we generate a solution $x_r$ and the corresponding y-vector as we did in **TASK 1, 1 f)**, and store them seperately as $x_{true}$ and $y_{SVD}$. Lastly, we use `Tikonov_solveSVD()` to calculate our $x_r$ and the error $\\|x_{true} - x_r\\|$, this for a range of $\\mu$-values. To make our code nicer, we implement this in a function we call `x_r_SVD()`, which returns all our $x_r$ vectors in a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f70133cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining som necessary variables\n",
    "m_SVD = 2048\n",
    "n_SVD = 8096\n",
    "\n",
    "# Generating random matrix A_SVD\n",
    "A_SVD = generate_A(m_SVD,n_SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c50e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1 # Number of test data we want to generate\n",
    "\n",
    "# Generate solutions X_SVD columnwise, X[:,i] to access i-th vector\n",
    "x_true = np.random.normal(0.0,1.0,(A_SVD.shape[1],N))\n",
    "\n",
    "# Generate left hand sides Y_SVD columnwise Y[:,i] to access lhs\n",
    "y_SVD = np.dot(A_SVD,x_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97db6b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_r_SVD(A_SVD,y_SVD,mu_vals):\n",
    "    \n",
    "    # Finding SVD decomposition of A_SVD\n",
    "    U,S,vt = np.linalg.svd(A_SVD)\n",
    "    \n",
    "    #create 2d-array for holding x_rs\n",
    "    x_r_matrix = np.zeros((n_SVD, len(mu_vals)))\n",
    "    \n",
    "    #iterate through mu values, calculate err and x_r for each\n",
    "    for i,mu in enumerate(mu_vals):\n",
    "        x_r_matrix[:,i] = Tikonov_solveSVD(U,S,vt,mu,y_SVD).flatten()\n",
    "    \n",
    "    #return x_r- and error values\n",
    "    return x_r_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114fddbe",
   "metadata": {},
   "source": [
    "Now that we have a way of finding our $x_r$ and the error $\\|x_{true} - x_r\\|$ for each $\\mu$, we want to compare it to `numpy.linalg.solve()`. For the NumPy implementation, we will only use 10 values $\\mu$ instead of 100 as we did for our SVD, as the NumPy approach should be much slower. We will also compare the runtime of each implementation, as well as the error for a given $\\mu$. We start by implementing a function `x_r_numpy()`, which finds our $x_r$ using `np.linalg.solve()`. Here we assume that $A^TA$ and $A^Ty$ are pre-calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3c1d2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_r_numpy(ATA, ATy, mu_vals):\n",
    "    \n",
    "    #create 2d-array for holding x_rs\n",
    "    x_r_matrix = np.zeros((len(ATA[:,0]), len(mu_vals)))\n",
    "    \n",
    "    #iterate through mu values, calculate err and x_r for each\n",
    "    for i,mu in enumerate(mu_vals):\n",
    "        x_r_matrix[:,i] = np.linalg.solve(ATA + mu * np.identity(len(ATA[:,0])), ATy).flatten()\n",
    "\n",
    "    #return x_r- and error values\n",
    "    return x_r_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add6c5b6",
   "metadata": {},
   "source": [
    "We now compare the runtime of our two implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d304fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating array of mu-values for SVD and numpy\n",
    "num_SVD = 20\n",
    "mu_vals_SVD = np.logspace(6,-6,num_SVD)\n",
    "\n",
    "num_numpy = 20\n",
    "mu_vals_numpy = np.logspace(6,-6,num_numpy)\n",
    "\n",
    "# calculating ATA and ATy\n",
    "ATA = A_SVD.T @ A_SVD\n",
    "ATy = A_SVD.T @ y_SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7501086e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 30s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "x_r_SVD(A_SVD,y_SVD,mu_vals_SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2eb9cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 4s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "x_r_numpy(ATA,ATy, mu_vals_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96092729",
   "metadata": {},
   "source": [
    "As we can see, NumPys `numpy.linalg.solve()` is somewhat faster than our implemented SVD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf537d4c",
   "metadata": {},
   "source": [
    "We now run our code again, and compare the norm  $\\|x_{true} - x_{min}\\|$ of methods using NumPy and SVD. Then plot both these norms for our range of values for $\\mu$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6ac7346",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating array of mu-values for SVD and numpy\n",
    "num_SVD = 100\n",
    "mu_vals_SVD = np.logspace(6,-6,num_SVD)\n",
    "\n",
    "num_numpy = 100\n",
    "mu_vals_numpy = np.logspace(6,-6,num_numpy)\n",
    "\n",
    "x_r_matrix_SVD = x_r_SVD(A_SVD,y_SVD,mu_vals_SVD)\n",
    "x_r_matrix_numpy = x_r_numpy(ATA,ATy,mu_vals_SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c634ff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create array for holding error values\n",
    "err_SVD = np.zeros(num_SVD)\n",
    "err_numpy = np.zeros(num_numpy)\n",
    "for i in range(num_SVD):\n",
    "    err_SVD[i] = np.linalg.norm(x_r_matrix_SVD[:,i].T - x_true.flatten())\n",
    "\n",
    "for i in range(num_numpy):\n",
    "    err_numpy[i] = np.linalg.norm(x_r_matrix_numpy[:,i].T - x_true.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2243b889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We plot our resulting norms for NumPy and SVD \n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title(\"Comparing norm of methods using NumPy and SVD\", fontsize = 20)\n",
    "plt.xlabel(\"$\\mu$\",fontsize = 16)\n",
    "plt.ylabel(\"$\\|x_{true} - x_r\\|$\", fontsize = 16)\n",
    "plt.plot(mu_vals_SVD,err_SVD, label = \"SVD\")\n",
    "plt.plot(mu_vals_numpy, err_numpy, label = \"NumPy\")\n",
    "plt.plot(mu_vals_SVD,[err_SVD[-1]]*100, \"--\", label = '$x_{min}$')\n",
    "plt.semilogx()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b76fffd",
   "metadata": {},
   "source": [
    "From the plot it seems that the error is smallest in the interval where $\\mu \\in [10^{-6},10]$, where the errors for SVD and NumPy seems to be identical. Intuitively this makes sense, as a weight means that the term $\\|Ax -y\\|^2$ will dominate in our $T(x)$. Since we arent as interested in minimizing the norm $\\|x\\|$, it makes sense that we get the smallest norm $\\|x_{true} - x_r\\|$ when our weight  $\\mu$ is small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f724663",
   "metadata": {},
   "source": [
    "## TASK 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cb1310",
   "metadata": {},
   "source": [
    "In this segment, we will look closer at solving the single channel source separation using learnt norm. In our application, we will use it to split a set of images into two categories; zeros and ones. Here we will import the MNIST data set, which was given as a attachment to this project. The images are stored in a matrix with values in $[0,1]$, where the columns are representative of a given image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96202c28",
   "metadata": {},
   "source": [
    "### 3 a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b0a5e7",
   "metadata": {},
   "source": [
    "We start by showing that a matrix $B = I - WW^T$ is a projection matrix, with $W \\in{\\rm I\\!R}^{m \\times n}$ being a matrix containing pairwise orthogonal columns and $I$ being the identity matrix. We note that if a given matrix $A$ is a projection matrix, then $A^2 = A$. Furthermore, pairwise orthogonality means that the columns $(w_1,w_2,...,w_n)$ of $W$ satisfy that $\\langle w_i,w_j \\rangle = 0$, for $i \\neq j$.\n",
    "\n",
    "To prove that $B$ is a projection matrix, we first look at $B^2$: <br><br>\n",
    "$$\n",
    "\\begin{aligned}\n",
    "B^2 = (I - WW^T)^2 &=(I - WW^T)(I - WW^T)  \\\\\n",
    "&= I^2 -2WW^T + (WW^T)(WW^T) \\\\\n",
    "&= I^2 -2WW^T + W(W^TW)W^T \n",
    "\\end{aligned}\n",
    "$$\n",
    "<br>\n",
    " Using that $w_i^Tw_j= \\langle w_i,w_j \\rangle$, we write out $W^TW$ on component form.\n",
    "$$\n",
    "W^TW =\\begin{bmatrix}w_1^T\\\\w_2^T\\\\\\vdots\\\\w_n^T\\end{bmatrix} [w_1,w_2, ... , w_n] = \n",
    "\\begin{bmatrix}\n",
    "\\langle w_1,w_1 \\rangle & \\langle w_1,w_2 \\rangle &\\ldots& \\langle w_1,w_n \\rangle\\\\\n",
    "\\langle w_2,w_1 \\rangle & \\langle w_2,w_2 \\rangle &\\ldots& \\langle w_2,w_n \\rangle\\\\\n",
    "\\vdots & \\vdots &&\\vdots\\\\\n",
    "\\langle w_n,w_1 \\rangle & \\langle w_n,w_2 \\rangle &\\ldots& \\langle w_n,w_n \\rangle\\\\\n",
    "\\end{bmatrix}\n",
    "$$ \n",
    "\n",
    "Knowing that the columns $(w_1,w_2,...,w_n)$ of $W$ are pairwise orthogonal, we have that $\\langle w_i,w_j \\rangle = 0 $ for all $ i \\neq j$, and  $\\langle w_i,w_j \\rangle = 1 $ for $ i = j$. Thus,\n",
    "\n",
    "$$\n",
    "W^TW =\\begin{bmatrix}w_1^T\\\\w_2^T\\\\\\vdots\\\\w_n^T\\end{bmatrix} [w_1,w_2, ... , w_n] = \n",
    "\\begin{bmatrix}\n",
    "1 & 0 &\\ldots& 0\\\\\n",
    "0 & 1 &\\ldots& 0 \\rangle\\\\\n",
    "\\vdots & \\vdots &&\\vdots\\\\\n",
    "0 &0 &\\ldots& 1\\\\\n",
    "\\end{bmatrix} = I\n",
    "$$ \n",
    "\n",
    "Placing this into our equation for $B^2$, we get the following.<br><br>\n",
    "$$\n",
    "B^2 = I^2 -2WW^T + W(I)W^T = I - 2WW^T +WW^T = I -WW^T = B\n",
    "$$\n",
    "$$\n",
    "\\Rightarrow B^2 = B \n",
    "$$\n",
    "<br>\n",
    "Now that we have shown $B$ is a projection matrix, we want to show that it is symmetric positive semi-definite. To do this, we look at the eigenvalues $\\lambda$ and eigenvectors $x$ of $B$, such that $Bx = \\lambda x$:\n",
    "<br>\n",
    "$$\n",
    "B^2x = B(Bx) = B(\\lambda x) = \\lambda(Bx) = \\lambda^2x\n",
    "$$\n",
    "$$\n",
    "\\Rightarrow B^2x = \\lambda^2x \n",
    "$$\n",
    "<br>\n",
    "But as we showed earlier $B$ is a projection matrix, $B^2 = B$.\n",
    "Then,\n",
    "<br>\n",
    "$$\n",
    "Bx = B^2x =  \\lambda^2 x \\wedge Bx = \\lambda x\n",
    "$$\n",
    "$$\n",
    "\\Rightarrow \\lambda^2 = \\lambda \\iff \\lambda = 0 \\vee \\lambda = 1\n",
    "$$\n",
    "<br>\n",
    "Thus, we have shown that our projection matrix $B$ (and all other projection matrices for that matter), can only have the two eigenvalues $\\lambda = 0$ and $\\lambda = 1$. As these eigenvalues are non-negative (but not strictly positive), we only now need to show that $B^T = B$ to prove that our $B$ is symmetric positive semi-definite, SPSD. \n",
    "$$\n",
    "B^T = (I - WW^T)^T = I^T - (WW^T)^T = I - WW^T = B\n",
    "$$\n",
    "\n",
    "As shown $B^T = B$, thus we can conclude that $B$ is SPSD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b1e0c9",
   "metadata": {},
   "source": [
    "### 3 b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f1f68d",
   "metadata": {},
   "source": [
    "For this task, we want to find the minimal norm, meaning that we want to find \n",
    "$$\n",
    "\\text{arg}_x min \\frac{1}{2}x^TBx, \\hspace{0.5cm} \\text{such that}\\hspace{0.2cm} Ax = y\n",
    "$$\n",
    ",where $A$, $B$ and $x$ are defined as\n",
    "$$\n",
    "A = [I\\quad I] \\quad B=\\begin{bmatrix}B_0&0\\\\0&B_1\\end{bmatrix},\\quad B_0 = I-W_0W_0^T,\\quad B_1=I-W_1W_1^T,\\quad \\boldsymbol{x}=\\begin{bmatrix}\\boldsymbol{u}\\\\\\boldsymbol{v}\\end{bmatrix} .\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f59b48",
   "metadata": {},
   "source": [
    "### 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c119c7",
   "metadata": {},
   "source": [
    "Similarly to **TASK 1, 1 c)**, we have a lagrange function which is defined as <br><br>\n",
    "$$ \n",
    "L(x,\\lambda) = x^TBx + \\lambda^T(Ax - y)\n",
    "$$\n",
    "<br>\n",
    ",which we wish to find $x$ such that the the gradient of our lagrange function is equal to zero.<br>\n",
    "We start by looking at $\\nabla_x L(x,\\lambda)$, using our results from **TASK 1, 1 c)**:<br><br>\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\nabla_x L(x,\\lambda) &= \\frac{d}{dx} (x^TBx) + \\frac{d}{dx} (\\lambda^T(Ax - y))\\\\\n",
    "&= (\\frac{1}{2}B^T +\\frac{1}{2}B)x + A^T \\lambda\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\nabla_{\\lambda} L(x,\\lambda) &= \\frac{d}{d\\lambda} (x^TBx) + \\frac{d}{d\\lambda} (\\lambda^T(Ax - y)) = Ax-y\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43703699",
   "metadata": {},
   "source": [
    "Setting these equations to zero, we can rewrite this into a system of equations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a05d56a",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix}\\ \\frac{1}{2}B^T +\\frac{1}{2}B & A^T\\\\A&0\\end{bmatrix} \\begin{bmatrix}x\\\\ \\lambda \\end{bmatrix} = \\begin{bmatrix}0\\\\ y \\end{bmatrix}\n",
    "$$\n",
    "Here 0 are suitably sized matrices containing only 0. We now swap out $A$, $B$ and $x$ for the expressions we defined earlier, also noting that $B^T = B$, such that $\\frac{1}{2}B^T +\\frac{1}{2}B = B$.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\\ I-W_0W_0^T& 0& I\\\\ 0&I-W_1W_1^T&I\\\\ I&I& 0\\end{bmatrix} \\begin{bmatrix}u\\\\v\\\\ \\lambda \\end{bmatrix} = \\begin{bmatrix}0\\\\0\\\\ y \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330a0e79",
   "metadata": {},
   "source": [
    "### 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722cc928",
   "metadata": {},
   "source": [
    "We now wish to eliminate $\\lambda$ from our system of equations above. We do this by writing out our system as three equations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2fa36f",
   "metadata": {},
   "source": [
    "$$\n",
    "(I-W_0W_0^T)u + I\\lambda = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "(I-W_1W_1^T)v I\\lambda = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "u+v=y\n",
    "$$\n",
    "\n",
    "We now subtract the first equation from our second. \n",
    "\n",
    "$$\n",
    "(I-W_1W_1^T)v + I\\lambda - ((I-W_0W_0^T)u + I\\lambda) = (I-W_1W_1^T)v - (I-W_0W_0^T)u = 0\n",
    "$$\n",
    "\n",
    "Rewriting our 3rd equation as $v = y-u$, we can further rewrite our system.\n",
    "\n",
    "$$\n",
    "(I-W_1W_1^T)(y-u) - (I-W_0W_0^T)u = 0\n",
    "$$\n",
    "$$\n",
    "\\Rightarrow (2I-W_0W_0^T-W_1W_1^T)u = (I-W_1W_1^T)y\n",
    "$$\n",
    "<br>\n",
    "From our last equation, we see that it is possible to write our system of equations as $Cu = d$ with <br><br>\n",
    "$$\n",
    "C = (2I-W_0W_0^T-W_1W_1^T) \\hspace{0.5cm}, d = (I-W_1W_1^T)y\n",
    "$$\n",
    "<br>\n",
    "It is clear that when we have solved $Cu = d$ for $u$, we can find $v$ using that $v = y - u$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd52d84a",
   "metadata": {},
   "source": [
    "### 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944d9cd0",
   "metadata": {},
   "source": [
    "Now that we have found the necessary equations for calculating $u$ and $v$, we now try to implement a method for solving our system using the minimal norm approach. To do this, we will use the QR-decomposition found in NumPys `numpy.linalg.qr()`, as well as the previously implemented function `QR_solver()`. The choice of using QR-decomposition as our system is quite somewhat large. All though the QR-decomposition itself is quite computationally heavy, our use of `QR_solver()` has shown to be quite fast. The reason for choosing `numpy.linalg.qr()` in favour of our own implemented `gram_schmidt()`, is because the Gram-Schmidt method is known to be numerically unstable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5479cc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_minimizor(W0,W1, mixed):\n",
    "    \n",
    "    n = np.shape(W0)[0]\n",
    "    \n",
    "    I = np.identity(n)\n",
    "    u_vals = np.zeros((n,n))\n",
    "    v_vals = np.zeros((n,n))\n",
    "    \n",
    "    # Calculate C matrix\n",
    "    C = 2*I - W0 @ W0.T - W1 @ W1.T\n",
    "    \n",
    "    #Find QR-decomposition of C\n",
    "    Q,R = np.linalg.qr(C)\n",
    "    \n",
    "    # Calculate d, and then u and v for each picture in mixed\n",
    "    for i,y in enumerate(mixed.T):\n",
    "        d = (I -W1 @ W1.T) @ y\n",
    "        \n",
    "        u =  QR_solver(Q, R, d)\n",
    "        u_vals[i] = u\n",
    "        \n",
    "        v = y - u\n",
    "        v_vals[i] = v\n",
    "    \n",
    "    # Return u's and v's for each picture\n",
    "    return u_vals, v_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21898ec1",
   "metadata": {},
   "source": [
    "Now that we have implemented the necessary code, we apply ut to a set of images, and look at the runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06ef8e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a matrix with shape (784 x 100),\n",
    "# 100 columns each representing a image with 784 pixels\n",
    "mixed = np.load('mixed.npy')\n",
    "W0 = np.load('W0.npy')\n",
    "W1 = np.load('W1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49c9ec6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431 ms ± 17.5 ms per loop (mean ± std. dev. of 6 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 6 \n",
    "norm_minimizor(W0,W1,mixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f75214",
   "metadata": {},
   "source": [
    "As we can see, our developed method is we quite fast. Now we plot our $u$ and $v$ to see if this approach works for single source separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc5b74f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_vals, v_vals = norm_minimizor(W0,W1,mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22748d76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x192c1094d00>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot a picture, u and v separately\n",
    "\n",
    "figure, (ax1,ax2,ax3) = plt.subplots(1,3)\n",
    "figure.set_figheight(12)\n",
    "figure.set_figwidth(12)\n",
    "\n",
    "ax1.set_title(\"Original picture\")\n",
    "ax2.set_title(\"Seperated channel with zero\")\n",
    "ax3.set_title(\"Seperated channel with one\")\n",
    "\n",
    "ax1.imshow(mixed[:,1].reshape((28,28)), cmap = 'gray')\n",
    "ax2.imshow(u_vals[1].reshape((28,28)), cmap = 'gray')\n",
    "ax3.imshow(v_vals[1].reshape((28,28)), cmap = 'gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5db032",
   "metadata": {},
   "source": [
    "Qualitatively, it seems that we are able to separate our two channels realtively well, all though we do see some remaining \"noise\" in our separated images. Still, we have a reasonable argument for saying that the single source separation we have performed, has infact given a meaningful separation. However, a clear drawback in our implementation is that it is heavily dependent on knowing our bases $W_0$ and $W_1$. Without knowing these, we cant use this method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
